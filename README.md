# PAPERS to READ(ICCV 2019)

Focus on Multimodal(Text & Image), CrossModal

â€‹	keyword: __Attention, Graph, Zero shot__

---

- [Making History Matter: History-Advantage Sequence Training for Visual Dialog](https://arxiv.org/abs/1902.09326)

- [Scene Graph Prediction With Limited Labels](https://arxiv.org/abs/1904.11622)
- [Align2Ground: Weakly Supervised Phrase Grounding Guided by Image-Caption Alignment](https://arxiv.org/abs/1903.11649)

- [Learning to Collocate Neural Modules for Image Captioning](https://arxiv.org/abs/1904.08608)

- [G3raphGround: Graph-Based Language Grounding](http://openaccess.thecvf.com/content_ICCV_2019/papers/Bajaj_G3raphGround_Graph-Based_Language_Grounding_ICCV_2019_paper.pdf)

- [Scene Text Visual Question Answering](https://arxiv.org/abs/1905.13648)

- [CAMP: Cross-Modal Adaptive Message Passing for Text-Image Retrieval](https://arxiv.org/abs/1909.05506)

- [ACMM: Aligned Cross-Modal Memory for Few-Shot Image and Sentence Matching](http://openaccess.thecvf.com/content_ICCV_2019/papers/Huang_ACMM_Aligned_Cross-Modal_Memory_for_Few-Shot_Image_and_Sentence_Matching_ICCV_2019_paper.pdf)

- [Adversarial Representation Learning for Text-to-Image Matching](https://arxiv.org/abs/1908.10534)

- [Multi-Modality Latent Interaction Network for Visual Question Answering](https://arxiv.org/abs/1908.04289)

- [Transferable Representation Learning in Vision-and-Language Navigation](https://arxiv.org/abs/1908.03409)

- [Towards Unsupervised Image Captioning With Shared Multimodal Embeddings](https://arxiv.org/abs/1908.09317)

- [Language Features Matter: Effective Language Representations for Vision-Language Tasks](https://arxiv.org/abs/1908.06327)

- [Language-Conditioned Graph Networks for Relational Reasoning](https://arxiv.org/abs/1905.04405)

- [Relation-Aware Graph Attention Network for Visual Question Answering](https://arxiv.org/abs/1903.12314)

- [Tell, Draw, and Repeat: Generating and Modifying Images Based on Continual Linguistic Instruction](https://arxiv.org/abs/1811.09845)

  

---

## ORAL

- [Learning Combinatorial Embedding Networks for Deep Graph Matching](https://arxiv.org/pdf/1904.00597.pdf)
- [Fashion Retrieval via Graph Reasoning Networks on a Similarity Pyramid](https://arxiv.org/abs/1908.11754)
- [A Graph-Based Framework to Bridge Movies and Synopses](https://arxiv.org/abs/1910.11009)
- [From Strings to Things: Knowledge-Enabled VQA Model That Can Read and Reason](http://openaccess.thecvf.com/content_ICCV_2019/papers/Singh_From_Strings_to_Things_Knowledge-Enabled_VQA_Model_That_Can_Read_ICCV_2019_paper.pdf)
- [Counterfactual Critic Multi-Agent Training for Scene Graph Generation](https://arxiv.org/abs/1812.02347)
- [Attention on Attention for Image Captioning](https://arxiv.org/abs/1908.06954)
- [Dynamic Graph Attention for Referring Expression Comprehension](https://arxiv.org/abs/1909.08164)

- [Zero-Shot Grounding of Objects From Natural Language Queries](https://arxiv.org/abs/1908.07129)
- [What Is Wrong With Scene Text Recognition Model Comparisons? Dataset and Model Analysis](https://arxiv.org/abs/1904.01906)